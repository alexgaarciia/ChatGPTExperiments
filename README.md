# LLMExperiments
## Goal of the repository
The main goal of this repository is to challenge different LLMs or, in other words, trying to discover the flaws of each of them. In particular we will be testing ChatGPT, Bard, Mistral and LLaMA. In order to do this properly, prompt engineering must be applied correctly to each of them (continue reading for further information).


## Large Langue Models
LLMs are a subset of machine learning models designed to understand and generate human-like text based on the data they have been trained on. Here are some characteristics:

1. Architecture: they use deep neural network architectures. DNNs are a type of artificial neural network with multiple layers between the input and the output layers. These intermediate layers allow DNNs to model and process complex patterns in large datasets.
2. Size: it is referred to as "large" because it has billions of parameters. These are the weights and biases in the neural network that are adjusted during training.
3. Training: training such models requires vast amounts of text data. This is key, since their outputs will depend on what they have "seen" before.
4. Limitations: they do not understand text in the way humans do; they can produce incorrect or nonsensical answers...


## ChatGPT for managing optical networks
One of the first tasks that we want to focus on is trying to understand how can ChatGPT be useful at managing optical networks. Surprisingly, it can be used for many things along the lines of:

1. Design and Planning:
- Assist in bandwidth estimation and demand forecasting.
- Provide guidance on choosing between optical technologies based on the application.

2. Fault Diagnosis:
- If we describe specific problems, it can help pinpointing potential causes.
- Suggest procedures for optical network troubleshooting.

3. Optimization:
- Tips on optimizing the signal quality, reducing bit error rates and maximizing the available bandwidth.


## Correct prompting
In order to test properly how a LLM performs, it is a must to know how to correctly prompt it. Prompting is any form of text, question, information, or coding that communicates to AI what response you are looking for. Each LLM has its own way of communicating, and we, as users, must be able to learn this. 

  